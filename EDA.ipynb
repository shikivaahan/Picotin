{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2dd8a8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "db7cd953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Date range boundaries\n",
    "start_date = pd.Timestamp('2024-12-01')\n",
    "end_date = pd.Timestamp('2025-03-31')\n",
    "\n",
    "def clean_itemgroup_data(file_path):\n",
    "    # Read Excel file\n",
    "    df = pd.read_excel(file_path, engine='xlrd', skiprows=4)\n",
    "    df = df[:-1]\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    df.columns = ['Date'] + list(df.columns[1:])\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    if 'Unnamed: 2' in df.columns:\n",
    "        df = df.drop(columns=['Unnamed: 2'])\n",
    "    \n",
    "    df = df[df['Date'] != 'Total']\n",
    "    df = df[df['Date'].notna()]\n",
    "    \n",
    "    # Drop columns with 'Unnamed' prefix\n",
    "    unnamed_columns = [col for col in df.columns if col.startswith('Unnamed')]\n",
    "    df = df.drop(columns=unnamed_columns)\n",
    "    \n",
    "    # Format the Date column\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%d-%b-%y')\n",
    "    \n",
    "    # Filter by date range\n",
    "    df = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)]\n",
    "    \n",
    "    # Convert the date back to the desired format\n",
    "    df['Date'] = df['Date'].dt.strftime('%m/%d/%Y')\n",
    "    \n",
    "    # Convert all columns except 'Date' to float, handling non-numeric values\n",
    "    for col in df.columns[1:]:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Calculate total_food and total_drinks for each row\n",
    "    food_cols = list(food.intersection(df.columns))\n",
    "    drink_cols = list(drinks.intersection(df.columns))\n",
    "\n",
    "    df['total_food'] = df[food_cols].sum(axis=1, skipna=True)\n",
    "    df['total_drinks'] = df[drink_cols].sum(axis=1, skipna=True)\n",
    "    \n",
    "    # Drop all columns except Date, total_food, total_drinks, Total\n",
    "    columns_to_keep = ['Date', 'total_food', 'total_drinks', 'Total']\n",
    "    df = df[[col for col in columns_to_keep if col in df.columns]]\n",
    "    \n",
    "    # Convert column names to lowercase\n",
    "    df.columns = df.columns.str.lower()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def clean_daily_summary(file_path):\n",
    "    # Read CSV file with appropriate skipping of rows and footers\n",
    "    df = pd.read_csv(file_path, skiprows=4, skipfooter=7, engine='python')\n",
    "    \n",
    "    # Drop unnamed columns\n",
    "    unnamed_columns = [col for col in df.columns if col.startswith('Unnamed:')]\n",
    "    df.drop(columns=unnamed_columns, inplace=True)\n",
    "    \n",
    "    # Convert START column to date format\n",
    "    df['START'] = pd.to_datetime(df['START'], format='%d/%m/%Y %H:%M:%S')\n",
    "    \n",
    "    # Filter by date range\n",
    "    df = df[(df['START'] >= start_date) & (df['START'] <= end_date)]\n",
    "    \n",
    "    # Format the date to the desired format\n",
    "    df['START'] = df['START'].dt.strftime('%d/%m/%Y')\n",
    "    \n",
    "    # Drop all other columns except START, ORDERS COUNT, AVG ORDER\n",
    "    columns_to_keep = ['START', 'ORDERS COUNT', 'AVG ORDER']\n",
    "    df = df[[col for col in columns_to_keep if col in df.columns]]\n",
    "    \n",
    "    # Rename START to date\n",
    "    df.rename(columns={'START': 'date'}, inplace=True)\n",
    "    \n",
    "    # Convert all column names to lowercase\n",
    "    df.columns = df.columns.str.lower()\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0afc340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASQ_itemgroup = clean_itemgroup_data(r'daily_data\\ASQ_itemgroup_daily.xls')\n",
    "ASQ_daily_summary = clean_daily_summary(r'daily_data\\KATONG_daily_summary.csv')\n",
    "\n",
    "KATONG_itemgroup = clean_itemgroup_data(r'daily_data\\KATONG_itemgroup_daily.xls')\n",
    "KATONG_daily_summary = clean_daily_summary(r'daily_data\\KATONG_daily_summary.csv')\n",
    "\n",
    "RC_itemgroup = clean_itemgroup_data(r'daily_data\\RC_itemgroup_daily.xls')\n",
    "RC_daily_summary = clean_daily_summary(r'daily_data\\RC_daily_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ec0f9a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12     12/01/2024\n",
       "13     12/02/2024\n",
       "14     12/03/2024\n",
       "16     12/04/2024\n",
       "17     12/05/2024\n",
       "          ...    \n",
       "147    03/27/2025\n",
       "149    03/28/2025\n",
       "150    03/29/2025\n",
       "151    03/30/2025\n",
       "152    03/31/2025\n",
       "Name: date, Length: 121, dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RC_itemgroup['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "38c7868e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11     02/12/2024\n",
       "12     03/12/2024\n",
       "13     04/12/2024\n",
       "14     04/12/2024\n",
       "15     06/12/2024\n",
       "          ...    \n",
       "125    26/03/2025\n",
       "126    27/03/2025\n",
       "127    28/03/2025\n",
       "128    29/03/2025\n",
       "129    30/03/2025\n",
       "Name: date, Length: 119, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RC_daily_summary['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ccfc2b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates missing in RC_itemgroup: [Timestamp('2024-12-02 00:00:00'), Timestamp('2024-12-03 00:00:00'), Timestamp('2024-12-04 00:00:00'), Timestamp('2024-12-06 00:00:00'), Timestamp('2024-12-07 00:00:00'), Timestamp('2024-12-08 00:00:00'), Timestamp('2024-12-09 00:00:00'), Timestamp('2024-12-10 00:00:00'), Timestamp('2024-12-11 00:00:00'), Timestamp('2024-12-13 00:00:00'), Timestamp('2024-12-14 00:00:00'), Timestamp('2024-12-15 00:00:00'), Timestamp('2024-12-16 00:00:00'), Timestamp('2024-12-17 00:00:00'), Timestamp('2024-12-18 00:00:00'), Timestamp('2024-12-19 00:00:00'), Timestamp('2024-12-20 00:00:00'), Timestamp('2024-12-21 00:00:00'), Timestamp('2024-12-22 00:00:00'), Timestamp('2024-12-23 00:00:00'), Timestamp('2024-12-25 00:00:00'), Timestamp('2024-12-26 00:00:00'), Timestamp('2024-12-27 00:00:00'), Timestamp('2024-12-28 00:00:00'), Timestamp('2024-12-29 00:00:00'), Timestamp('2024-12-30 00:00:00'), Timestamp('2024-12-31 00:00:00'), Timestamp('2025-01-04 00:00:00'), Timestamp('2025-01-05 00:00:00'), Timestamp('2025-01-06 00:00:00'), Timestamp('2025-01-07 00:00:00'), Timestamp('2025-01-08 00:00:00'), Timestamp('2025-01-09 00:00:00'), Timestamp('2025-01-10 00:00:00'), Timestamp('2025-01-11 00:00:00'), Timestamp('2025-01-12 00:00:00'), Timestamp('2025-01-13 00:00:00'), Timestamp('2025-01-14 00:00:00'), Timestamp('2025-01-15 00:00:00'), Timestamp('2025-01-16 00:00:00'), Timestamp('2025-01-17 00:00:00'), Timestamp('2025-01-19 00:00:00'), Timestamp('2025-01-20 00:00:00'), Timestamp('2025-01-21 00:00:00'), Timestamp('2025-01-22 00:00:00'), Timestamp('2025-01-23 00:00:00'), Timestamp('2025-01-24 00:00:00'), Timestamp('2025-01-25 00:00:00'), Timestamp('2025-01-26 00:00:00'), Timestamp('2025-01-27 00:00:00'), Timestamp('2025-01-28 00:00:00'), Timestamp('2025-01-29 00:00:00'), Timestamp('2025-01-30 00:00:00'), Timestamp('2025-01-31 00:00:00'), Timestamp('2025-02-04 00:00:00'), Timestamp('2025-02-05 00:00:00'), Timestamp('2025-02-06 00:00:00'), Timestamp('2025-02-07 00:00:00'), Timestamp('2025-02-08 00:00:00'), Timestamp('2025-02-09 00:00:00'), Timestamp('2025-02-10 00:00:00'), Timestamp('2025-02-11 00:00:00'), Timestamp('2025-02-12 00:00:00'), Timestamp('2025-02-13 00:00:00'), Timestamp('2025-02-14 00:00:00'), Timestamp('2025-02-15 00:00:00'), Timestamp('2025-02-16 00:00:00'), Timestamp('2025-02-17 00:00:00'), Timestamp('2025-02-18 00:00:00'), Timestamp('2025-02-19 00:00:00'), Timestamp('2025-02-20 00:00:00'), Timestamp('2025-02-21 00:00:00'), Timestamp('2025-02-22 00:00:00'), Timestamp('2025-02-23 00:00:00'), Timestamp('2025-02-24 00:00:00'), Timestamp('2025-02-25 00:00:00'), Timestamp('2025-02-26 00:00:00'), Timestamp('2025-02-27 00:00:00'), Timestamp('2025-02-28 00:00:00'), Timestamp('2025-03-04 00:00:00'), Timestamp('2025-03-05 00:00:00'), Timestamp('2025-03-06 00:00:00'), Timestamp('2025-03-07 00:00:00'), Timestamp('2025-03-08 00:00:00'), Timestamp('2025-03-09 00:00:00'), Timestamp('2025-03-10 00:00:00'), Timestamp('2025-03-11 00:00:00'), Timestamp('2025-03-12 00:00:00'), Timestamp('2025-03-13 00:00:00'), Timestamp('2025-03-14 00:00:00'), Timestamp('2025-03-15 00:00:00'), Timestamp('2025-03-16 00:00:00'), Timestamp('2025-03-17 00:00:00'), Timestamp('2025-03-18 00:00:00'), Timestamp('2025-03-19 00:00:00'), Timestamp('2025-03-20 00:00:00'), Timestamp('2025-03-21 00:00:00'), Timestamp('2025-03-22 00:00:00'), Timestamp('2025-03-23 00:00:00'), Timestamp('2025-03-24 00:00:00'), Timestamp('2025-03-25 00:00:00'), Timestamp('2025-03-26 00:00:00'), Timestamp('2025-03-27 00:00:00'), Timestamp('2025-03-28 00:00:00'), Timestamp('2025-03-29 00:00:00'), Timestamp('2025-03-30 00:00:00')]\n",
      "Dates missing in RC_daily_summary: [Timestamp('2024-01-12 00:00:00'), Timestamp('2024-02-12 00:00:00'), Timestamp('2024-03-12 00:00:00'), Timestamp('2024-04-12 00:00:00'), Timestamp('2024-05-12 00:00:00'), Timestamp('2024-06-12 00:00:00'), Timestamp('2024-07-12 00:00:00'), Timestamp('2024-08-12 00:00:00'), Timestamp('2024-09-12 00:00:00'), Timestamp('2024-10-12 00:00:00'), Timestamp('2024-11-12 00:00:00'), Timestamp('2025-04-01 00:00:00'), Timestamp('2025-04-02 00:00:00'), Timestamp('2025-04-03 00:00:00'), Timestamp('2025-05-01 00:00:00'), Timestamp('2025-05-02 00:00:00'), Timestamp('2025-05-03 00:00:00'), Timestamp('2025-06-01 00:00:00'), Timestamp('2025-06-02 00:00:00'), Timestamp('2025-06-03 00:00:00'), Timestamp('2025-07-01 00:00:00'), Timestamp('2025-07-02 00:00:00'), Timestamp('2025-07-03 00:00:00'), Timestamp('2025-08-01 00:00:00'), Timestamp('2025-08-02 00:00:00'), Timestamp('2025-08-03 00:00:00'), Timestamp('2025-09-01 00:00:00'), Timestamp('2025-09-02 00:00:00'), Timestamp('2025-09-03 00:00:00'), Timestamp('2025-10-01 00:00:00'), Timestamp('2025-10-02 00:00:00'), Timestamp('2025-10-03 00:00:00'), Timestamp('2025-11-01 00:00:00'), Timestamp('2025-11-02 00:00:00'), Timestamp('2025-11-03 00:00:00'), Timestamp('2025-12-01 00:00:00'), Timestamp('2025-12-02 00:00:00'), Timestamp('2025-12-03 00:00:00')]\n",
      "\n",
      "Duplicate dates in RC_daily_summary: <DatetimeArray>\n",
      "['2024-12-04 00:00:00', '2024-12-23 00:00:00', '2025-01-17 00:00:00']\n",
      "Length: 3, dtype: datetime64[ns]\n",
      "Duplicate dates in RC_itemgroup: <DatetimeArray>\n",
      "['NaT']\n",
      "Length: 1, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the date columns to datetime for accurate comparison\n",
    "RC_daily_summary['date'] = pd.to_datetime(RC_daily_summary['date'], dayfirst=True, errors='coerce')\n",
    "RC_itemgroup['date'] = pd.to_datetime(RC_itemgroup['date'], dayfirst=True, errors='coerce')\n",
    "\n",
    "# Find unique dates from both DataFrames\n",
    "summary_dates = set(RC_daily_summary['date'].dropna().unique())\n",
    "itemgroup_dates = set(RC_itemgroup['date'].dropna().unique())\n",
    "\n",
    "# Find missing dates\n",
    "missing_in_itemgroup = summary_dates - itemgroup_dates\n",
    "missing_in_summary = itemgroup_dates - summary_dates\n",
    "\n",
    "# Find duplicate dates in each DataFrame\n",
    "duplicates_in_summary = RC_daily_summary['date'][RC_daily_summary['date'].duplicated()]\n",
    "duplicates_in_itemgroup = RC_itemgroup['date'][RC_itemgroup['date'].duplicated()]\n",
    "\n",
    "# Display the results\n",
    "print(\"Dates missing in RC_itemgroup:\", sorted(missing_in_itemgroup))\n",
    "print(\"Dates missing in RC_daily_summary:\", sorted(missing_in_summary))\n",
    "print(\"\\nDuplicate dates in RC_daily_summary:\", duplicates_in_summary.unique())\n",
    "print(\"Duplicate dates in RC_itemgroup:\", duplicates_in_itemgroup.unique())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
